如果网页的链接地址改变了,在通过这个地址访问的时候会返回一个错误码404. 表示没有找到该地址内容.

这个在建站初期是很容易发生的事.我的文章开始是通过中文名作为URL的，后来改为数字作为URL.这时网上已经有很多文章中存储了以前的已经失效的地址.

这样导致搜索引擎抓取网页时会有大量的失效链接.

死连数量多会导致搜索引擎降权, 我的网站dashidan.com就没有被bing收录.很惨痛的教训。

针对404有2种补救措施。发生404错误时指向404.html页面或者做网页重定向.

1 Nginx设置404错误指向页面
===

nginx默认配置中是这样的：

```
location / {
		# First attempt to serve request as file, then
		# as directory, then fall back to displaying a 404.
		try_files $uri $uri/ =404;
}
```

其中try_files是nginx解析网站地址的过程, 找不到的话返回404错误.把最后的404改为404.html,表示返回404.html页面.

```
try_files $uri $uri/ =/404.html;
```

2 制作一个404.html页面
===

可以做一个静态html页面来作为道歉页面.参考页面[http://dashidan.com/404.html](http://dashidan.com/404.html).

3 重启Nginx使配置生效
===

重启完成后,可以输入一个域名后并不存在的页面来查看效果.


4 避免出现404错误
===

网页避免出现404错误的最佳方案是在设计网站之初对整体的URL做好完整的规划. 否则只能在出现问题后补救了.
以大屎蛋教程网的url规划为例：

- 文章均放在article目录
- 文章根据语言分类 article/java, article/mongodb...
- 图片放在img目录
- 下载资源放在download目录
- css文件放在css目录
- js脚本文件放在js目录

有了合理的规划就能最大程度避免出现404错误.

5 roboot.txt屏蔽404页面
===

在roboot.txt文件中加入死链url, 来避免搜索引擎访问已失效的网页.也是针对404错误的一种补救措施.

通过robot设置屏蔽指定网页的方式：
```
User-agent: *
Disallow: /article/java/basic/屏蔽.html
```